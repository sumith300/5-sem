{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6142f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"I loved the design of the laptop, but the performance was slow and disappointing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01f92e",
   "metadata": {},
   "source": [
    "1. Perform tokenization on the given review and print the list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e071d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['I', 'loved', 'the', 'design', 'of', 'the', 'laptop', 'but', 'the', 'performance', 'was', 'slow', 'and', 'disappointing']\n"
     ]
    }
   ],
   "source": [
    "# Simple tokenization using regex (keeps words, removes punctuation)\n",
    "import re\n",
    "tokens = re.findall(r\"\\w+\", text)\n",
    "print('Tokens:', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820a2ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags: [('I', 'PRP'), ('loved', 'VBD'), ('the', 'DT'), ('design', 'NN'), ('of', 'IN'), ('the', 'DT'), ('laptop', 'NN'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('performance', 'NN'), ('was', 'VBD'), ('slow', 'JJ'), ('and', 'CC'), ('disappointing', 'JJ')]\n",
      "Adjectives: ['slow', 'disappointing']\n"
     ]
    }
   ],
   "source": [
    "# POS tagging using NLTK. Installs NLTK if it's not available and downloads required models.\n",
    "try:\n",
    "    import nltk\n",
    "except Exception:\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nltk'])\n",
    "    import nltk\n",
    "# download quietly (won't re-download if already present)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "from nltk import word_tokenize, pos_tag\n",
    "tokens = word_tokenize(text)\n",
    "pos_tags = pos_tag(tokens)\n",
    "print('POS tags:', pos_tags)\n",
    "# Extract adjectives (JJ, JJR, JJS)\n",
    "adjectives = [w for w, t in pos_tags if t.startswith('JJ')]\n",
    "print('Adjectives:', adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9743182",
   "metadata": {},
   "source": [
    "### What the adjectives reveal\n",
    "The extracted adjectives show the customer's opinion words. Positive adjectives (e.g., 'loved' is a verb expressing positive sentiment) and negative adjectives like 'slow' or 'disappointing' (if tagged as adjectives) indicate mixed feedback: the customer likes the design but is unhappy with performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8d1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastlaptopoffer -> fast laptop offer\n",
      "discountonbatterylife -> discount on battery life\n",
      "buyelectronicsonline -> buy electronics online\n"
     ]
    }
   ],
   "source": [
    "# Dictionary-based segmentation (word break)\n",
    "vocab = {\n",
    "    'laptop','design','performance','fast','offer','discount','battery','life',\n",
    "    'buy','electronics','electronic','online','on','sale','price','cheap',\n",
    "    'quality','shipping','warranty','display','processor','ram','storage'\n",
    "}\n",
    "def segment_query(query, vocab):\n",
    "    n = len(query)\n",
    "    dp = [False] * (n+1)\n",
    "    dp[0] = True\n",
    "    back = [-1] * (n+1)\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(0, i):\n",
    "            if dp[j] and query[j:i] in vocab:\n",
    "                dp[i] = True\n",
    "                back[i] = j\n",
    "                break\n",
    "    if not dp[n]:\n",
    "        return None\n",
    "    # reconstruct\n",
    "    words = []\n",
    "    i = n\n",
    "    while i>0:\n",
    "        j = back[i]\n",
    "        words.append(query[j:i])\n",
    "        i = j\n",
    "    return list(reversed(words))\n",
    "# queries to segment\n",
    "queries = ['fastlaptopoffer', 'discountonbatterylife', 'buyelectronicsonline']\n",
    "for q in queries:\n",
    "    seg = segment_query(q, vocab)\n",
    "    if seg:\n",
    "        print(q, '->', ' '.join(seg))\n",
    "    else:\n",
    "        # try small fallback: allow splitting into known prefixes like 'buy' + 'electronics' + 'online'\n",
    "        print(q, '->', 'No segmentation found with current vocabulary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
